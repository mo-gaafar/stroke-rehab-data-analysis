{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Plan\n",
    "\n",
    "- Download the data\n",
    "    - Place the dataset in data/stroke folder !!! (dont forget to do this)\n",
    "    - Load the data into a pandas dataframe?\n",
    "- Preprocess the signals\n",
    "    - Remove the noise\n",
    "    - Normalize the data\n",
    "- Feature extraction\n",
    "    - Extract features from the signals\n",
    "- Train the model\n",
    "    - Train the model using the extracted features\n",
    "- Evaluate the model\n",
    "    - Evaluate the model using the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "- Load the data into a pandas dataframe from matlab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/stroke/P1_pre_training.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32ml:\\Documents\\My Projects\\stroke-rehab-data-analysis\\.venv\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/stroke/P1_pre_training.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loadmat\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_1\u001b[39m\u001b[38;5;124m\"\u001b[39m : {\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[1;32m----> 8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/stroke/P1_pre_training.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P1_pre_test.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m         },\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPost\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P1_post_training.mat\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P1_post_test.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m         }\n\u001b[0;32m     15\u001b[0m     },\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_2\u001b[39m\u001b[38;5;124m\"\u001b[39m : {\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P2_pre_training.mat\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P2_pre_test.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m         },\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPost\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P2_post_training.mat\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P2_post_test.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m         }\n\u001b[0;32m     25\u001b[0m     },\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_3\u001b[39m\u001b[38;5;124m\"\u001b[39m : {\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P3_pre_training.mat\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P3_pre_test.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m         },\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPost\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P3_post_training.mat\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/stroke/P3_post_test.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m         }\n\u001b[0;32m     35\u001b[0m     },\n\u001b[0;32m     36\u001b[0m }\n",
      "File \u001b[1;32ml:\\Documents\\My Projects\\stroke-rehab-data-analysis\\.venv\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 225\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatfile_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32ml:\\Documents\\My Projects\\stroke-rehab-data-analysis\\.venv\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[1;32ml:\\Documents\\My Projects\\stroke-rehab-data-analysis\\.venv\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/stroke/P1_pre_training.mat'"
     ]
    }
   ],
   "source": [
    "# Load the data loadmat\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the data\n",
    "data_dict = {\n",
    "    \"Patient_1\" : {\n",
    "        \"Pre\":{\n",
    "            \"Train\": loadmat('data/stroke/P1_pre_training.mat'),\n",
    "            \"Test\": loadmat('data/stroke/P1_pre_test.mat')\n",
    "        },\n",
    "        \"Post\":{\n",
    "            \"Train\": loadmat('data/stroke/P1_post_training.mat'),\n",
    "            \"Test\": loadmat('data/stroke/P1_post_test.mat')\n",
    "        }\n",
    "    },\n",
    "    \"Patient_2\" : {\n",
    "        \"Pre\":{\n",
    "            \"Train\": loadmat('data/stroke/P2_pre_training.mat'),\n",
    "            \"Test\": loadmat('data/stroke/P2_pre_test.mat')\n",
    "        },\n",
    "        \"Post\":{\n",
    "            \"Train\": loadmat('data/stroke/P2_post_training.mat'),\n",
    "            \"Test\": loadmat('data/stroke/P2_post_test.mat')\n",
    "        }\n",
    "    },\n",
    "    \"Patient_3\" : {\n",
    "        \"Pre\":{\n",
    "            \"Train\": loadmat('data/stroke/P3_pre_training.mat'),\n",
    "            \"Test\": loadmat('data/stroke/P3_pre_test.mat')\n",
    "        },\n",
    "        \"Post\":{\n",
    "            \"Train\": loadmat('data/stroke/P3_post_training.mat'),\n",
    "            \"Test\": loadmat('data/stroke/P3_post_test.mat')\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to know the content of the data\n",
    "print(\"Data keys:\")\n",
    "\n",
    "print(data_dict[\"Patient_1\"][\"Pre\"][\"Train\"].keys())\n",
    "'''fs - sampling rate Hz\n",
    "y - EEG data (n_channels x n_samples)\n",
    "trig - trigger data (+1 left hand MI , -1 right hand MI)\n",
    "'''\n",
    "\n",
    "print(\"F sampling rate:\")\n",
    "print(data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"fs\"])\n",
    "print(\"EEG data shape (samples, channels):\")\n",
    "print(data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"y\"].shape)\n",
    "print(\"Trigger data shape:\")\n",
    "print(data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"trig\"].shape)\n",
    "\n",
    "\n",
    "'''Separate epochs for left and right hand MI'''\n",
    "from scripts import load_mne\n",
    "\n",
    "# data = load_mne(data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"y\"], data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"fs\"], data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"trig\"])\n",
    "mne_data_dict = load_mne.mne_load_data(data_dict=data_dict)\n",
    "\n",
    "# divide the eeg into epochs, each epoch is 8 seconds long (trigger is at 2 seconds, at 3.5 seconds )\n",
    "# One session was composed by 240 MI repetitions on both hands, divided in 3 runs of 80 trials each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne plots\n",
    "from scripts.spectro import plot_pseudospectrogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# spectrogram, event related spectral perturbation (ERSP) and inter-trial coherence (ITC)\n",
    "\n",
    "# SELECTING ONE PATIENT\n",
    "\n",
    "patient_epochs = mne_data_dict[\"Patient_2\"][\"Pre\"][\"Train\"]\n",
    "# print(mne_data_dict[\"Patient_2\"][\"Post\"].keys())\n",
    "# print(patient_epochs)\n",
    "# plot the spectrogram of the epoch using mne\n",
    "for key in patient_epochs.keys():\n",
    "    # plot for left and right\n",
    "    # plot_pseudospectrogram(patient_epochs[key])\n",
    "    # patient_epochs[key].plot_psd_topomap()\n",
    "    patient_epochs[key].compute_psd().plot()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# plot eeg and triggers for the first 10000 samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eeg_trigs = data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"trig\"][0, :]\n",
    "out_trigs = np.zeros_like(eeg_trigs)\n",
    "# find the triggers\n",
    "idx_array = []\n",
    "for i in range(len(eeg_trigs)):\n",
    "    if (eeg_trigs[i] != eeg_trigs[i-1]):\n",
    "        out_trigs.append(eeg_trigs[i])\n",
    "        idx_array.append(i)\n",
    "\n",
    "\n",
    "# Define the time axis and plot the data\n",
    "plt.figure(figsize=(10, 5))\n",
    "start_samples = 256 * 60 * 6\n",
    "width_samples = 256 * 60 * 2\n",
    "end_samples = width_samples+ start_samples\n",
    "data = data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"y\"]\n",
    "triggers = data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"trig\"]\n",
    "\n",
    "print(data.shape)\n",
    "time_axis = np.arange(start_samples, end_samples) / data_dict[\"Patient_1\"][\"Pre\"][\"Train\"][\"fs\"][0][0]\n",
    "plt.plot(time_axis, data[start_samples:end_samples, 0], label='Channel 1')\n",
    "# plt.plot(time_axis, data[start_samples:end_samples, 1], label='Channel 2')\n",
    "\n",
    "plt.plot(time_axis, triggers[start_samples:end_samples], label='Trigger')\n",
    "\n",
    "triggerd = np.zeros_like(triggers, dtype=int)\n",
    "triggerd[1:] = ((triggers[1:]-triggers[:-1])!=0) * (triggers[1:]!=0)\n",
    "triggerd[triggerd!=0] = triggers[triggerd!=0]\n",
    "events = np.column_stack((np.argwhere(triggerd)[:,0], np.zeros(sum(triggerd!=0), dtype=int),triggerd[triggerd!=0]))\n",
    "# print(events)\n",
    "\n",
    "plt.plot(time_axis, triggerd[start_samples:end_samples], label='Triggerdiff')\n",
    "\n",
    "plt.xlabel('Seconds')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Bandpass 8, 50 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter epochs using 3-50hz bandpass filter\n",
    "\n",
    "patient_epochs[\"left\"].filter(8, 50)\n",
    "patient_epochs[\"right\"].filter(8, 50)\n",
    "\n",
    "# remove blinking artifacts?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
